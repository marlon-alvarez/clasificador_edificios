{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# Clasificador de Edificios Urbanos — Entrenamiento de Modelos\n",
    "\n",
    "Este notebook implementa y compara tres arquitecturas de transfer learning para clasificar\n",
    "imágenes de edificaciones urbanas en 8 categorías.\n",
    "\n",
    "**Experimentos:**\n",
    "1. ResNet50 (backbone congelado)\n",
    "2. EfficientNetB0 (backbone congelado)\n",
    "3. MobileNetV2 (backbone congelado)\n",
    "4. Fine-tuning del mejor modelo\n",
    "\n",
    "**Seguimiento:** Todos los experimentos se registran en MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-config",
   "metadata": {},
   "source": [
    "## 1. Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando scikit-learn...\n",
      "Dependencias verificadas.\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependencias si es necesario\n",
    "import subprocess, sys\n",
    "\n",
    "required = [\n",
    "    \"mlflow\",\n",
    "    \"seaborn\",\n",
    "    \"tqdm\",\n",
    "    \"scikit-learn\",\n",
    "    \"pandas\",\n",
    "]\n",
    "\n",
    "for pkg in required:\n",
    "    try:\n",
    "        __import__(pkg.replace(\"-\", \"_\"))\n",
    "    except ImportError:\n",
    "        print(f\"Instalando {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
    "        \n",
    "print(\"Dependencias verificadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir : /Users/gerox/.cache/kagglehub/datasets/mikhailma/house-rooms-streets-image-dataset/versions/1/kaggle_room_street_data/street_data\n",
      "Exists   : True\n",
      "MLflow   : http://localhost:5000\n",
      "Clases   : ['apartment', 'church', 'garage', 'house', 'industrial', 'officebuilding', 'retail', 'roof']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ===========================================================================\n",
    "# CONFIGURACIÓN — ajusta estas rutas según el entorno (local / EC2)\n",
    "# ===========================================================================\n",
    "\n",
    "# Ruta al directorio con imágenes planas de street_data\n",
    "# Localmente: ~/.cache/kagglehub/...\n",
    "# En EC2:     establece la variable de entorno STREET_DATA_DIR\n",
    "_KAGGLE_CACHE = os.path.expanduser(\n",
    "    \"~/.cache/kagglehub/datasets/mikhailma/\"\n",
    "    \"house-rooms-streets-image-dataset/versions/1/\"\n",
    "    \"kaggle_room_street_data/street_data\"\n",
    ")\n",
    "DATA_DIR = os.getenv(\"STREET_DATA_DIR\", _KAGGLE_CACHE)\n",
    "\n",
    "# MLflow tracking URI\n",
    "# Local:  http://localhost:5000\n",
    "# EC2:    http://<EC2-PUBLIC-IP>:5000   o establece MLFLOW_TRACKING_URI\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "EXPERIMENT_NAME    = \"building_classifier\"\n",
    "\n",
    "# Hiperparámetros\n",
    "IMG_SIZE        = 224\n",
    "BATCH_SIZE      = 16\n",
    "INITIAL_EPOCHS  = 15\n",
    "FINE_TUNE_EPOCHS= 10\n",
    "INITIAL_LR     = 1e-3\n",
    "FINE_TUNE_LR   = 1e-5\n",
    "RANDOM_SEED     = 42\n",
    "\n",
    "# 8 clases (matchean el nombre en los archivos)\n",
    "CLASSES = [\n",
    "    'apartment', 'church', 'garage', 'house',\n",
    "    'industrial', 'officebuilding', 'retail', 'roof'\n",
    "]\n",
    "CLASS_LABELS = [\n",
    "    'Apartment', 'Church', 'Garage', 'House',\n",
    "    'Industrial', 'Office Bldg', 'Retail', 'Roof'\n",
    "]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "# Splits\n",
    "VAL_RATIO  = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "print(f\"Data dir : {DATA_DIR}\")\n",
    "print(f\"Exists   : {os.path.isdir(DATA_DIR)}\")\n",
    "print(f\"MLflow   : {MLFLOW_TRACKING_URI}\")\n",
    "print(f\"Clases   : {CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-imports",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"TensorFlow : {tf.__version__}\")\n",
    "print(f\"MLflow     : {mlflow.__version__}\")\n",
    "print(f\"GPUs       : {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-data",
   "metadata": {},
   "source": [
    "## 3. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(data_dir, categories):\n",
    "    \"\"\"Construye un DataFrame mapeando path de imagen → etiqueta.\n",
    "    Las imágenes están en un directorio plano con la clase en el nombre del archivo.\n",
    "    \"\"\"\n",
    "    paths, labels = [], []\n",
    "    for fname in tqdm(os.listdir(data_dir), desc=\"Escaneando archivos\"):\n",
    "        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "        fname_lower = fname.lower()\n",
    "        for cat in categories:\n",
    "            if cat in fname_lower:\n",
    "                paths.append(os.path.join(data_dir, fname))\n",
    "                labels.append(cat)\n",
    "                break\n",
    "    df = pd.DataFrame({'path': paths, 'label': labels})\n",
    "    df['label_idx'] = df['label'].map({c: i for i, c in enumerate(categories)})\n",
    "    return df\n",
    "\n",
    "df = build_dataframe(DATA_DIR, CLASSES)\n",
    "\n",
    "print(f\"Total imágenes cargadas: {len(df)}\")\n",
    "print(\"\\nDistribución por clase:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "counts = df['label'].value_counts().reindex(CLASSES)\n",
    "counts.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_title('Balance de clases en el dataset completo', fontweight='bold')\n",
    "ax.set_xlabel('Clase')\n",
    "ax.set_ylabel('Número de imágenes')\n",
    "ax.set_xticklabels(CLASS_LABELS, rotation=35, ha='right')\n",
    "for i, v in enumerate(counts):\n",
    "    ax.text(i, v + 30, str(v), ha='center', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split estratificado: 70% train | 15% val | 15% test\n",
    "X_paths = df['path'].values\n",
    "y_idx   = df['label_idx'].values\n",
    "\n",
    "X_train_p, X_temp_p, y_train, y_temp = train_test_split(\n",
    "    X_paths, y_idx,\n",
    "    test_size=(VAL_RATIO + TEST_RATIO),\n",
    "    stratify=y_idx,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "X_val_p, X_test_p, y_val, y_test = train_test_split(\n",
    "    X_temp_p, y_temp,\n",
    "    test_size=TEST_RATIO / (VAL_RATIO + TEST_RATIO),\n",
    "    stratify=y_temp,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train : {len(X_train_p):>6} imágenes ({len(X_train_p)/len(df)*100:.1f}%)\")\n",
    "print(f\"Val   : {len(X_val_p):>6} imágenes ({len(X_val_p)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test  : {len(X_test_p):>6} imágenes ({len(X_test_p)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-pipeline",
   "metadata": {},
   "source": [
    "## 4. Pipeline de Datos (tf.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa de aumentación de datos (solo se aplica en training)\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.15),\n",
    "    keras.layers.RandomZoom(0.10),\n",
    "    keras.layers.RandomContrast(0.10),\n",
    "], name=\"augmentation\")\n",
    "\n",
    "\n",
    "def load_image(path, label):\n",
    "    \"\"\"Lee y decodifica una imagen desde disco.\"\"\"\n",
    "    raw = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(raw, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def make_dataset(paths, labels, training=False, preprocess_fn=None):\n",
    "    \"\"\"Construye un tf.data.Dataset eficiente con caché y prefetch.\n",
    "\n",
    "    Args:\n",
    "        paths:        array de rutas de archivo\n",
    "        labels:       array de índices de clase\n",
    "        training:     si True, aplica shuffle + aumentación\n",
    "        preprocess_fn: función de preprocesamiento específica del backbone\n",
    "    Returns:\n",
    "        tf.data.Dataset listo para .fit()\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=4096, seed=RANDOM_SEED)\n",
    "        ds = ds.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "    if preprocess_fn is not None:\n",
    "        ds = ds.map(\n",
    "            lambda x, y: (preprocess_fn(x), y),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "print(\"Pipeline tf.data configurado.\")\n",
    "print(f\"  Batch size : {BATCH_SIZE}\")\n",
    "print(f\"  Aumentación: flip + rotación + zoom + contraste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-model",
   "metadata": {},
   "source": [
    "## 5. Fábrica de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-model-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de backbones disponibles\n",
    "BACKBONE_CONFIG = {\n",
    "    \"ResNet50\": {\n",
    "        \"builder\":    keras.applications.ResNet50,\n",
    "        \"preprocess\": keras.applications.resnet50.preprocess_input,\n",
    "    },\n",
    "    \"EfficientNetB0\": {\n",
    "        \"builder\":    keras.applications.EfficientNetB0,\n",
    "        \"preprocess\": keras.applications.efficientnet.preprocess_input,\n",
    "    },\n",
    "    \"MobileNetV2\": {\n",
    "        \"builder\":    keras.applications.MobileNetV2,\n",
    "        \"preprocess\": keras.applications.mobilenet_v2.preprocess_input,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def build_model(backbone_name):\n",
    "    \"\"\"Construye un modelo de clasificación con transfer learning.\n",
    "\n",
    "    Arquitectura:\n",
    "        Input (224×224×3)\n",
    "        → Backbone preentrenado en ImageNet (congelado)\n",
    "        → GlobalAveragePooling2D\n",
    "        → BatchNormalization\n",
    "        → Dropout(0.3)\n",
    "        → Dense(256, relu)\n",
    "        → Dropout(0.3)\n",
    "        → Dense(NUM_CLASSES, softmax)\n",
    "\n",
    "    Returns:\n",
    "        (model, preprocess_fn)\n",
    "    \"\"\"\n",
    "    cfg  = BACKBONE_CONFIG[backbone_name]\n",
    "    base = cfg[\"builder\"](\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    outputs = keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=f\"{backbone_name}_classifier\")\n",
    "    return model, cfg[\"preprocess\"]\n",
    "\n",
    "\n",
    "def unfreeze_top_layers(model, backbone_name, n_unfreeze=50):\n",
    "    \"\"\"Descongela las últimas n_unfreeze capas del backbone para fine-tuning.\"\"\"\n",
    "    backbone = model.layers[1]   # la capa base\n",
    "    backbone.trainable = True\n",
    "    freeze_until = max(0, len(backbone.layers) - n_unfreeze)\n",
    "    for layer in backbone.layers[:freeze_until]:\n",
    "        layer.trainable = False\n",
    "    trainable = sum(1 for l in backbone.layers if l.trainable)\n",
    "    print(f\"  Backbone: {len(backbone.layers)} capas totales, \"\n",
    "          f\"{trainable} descongeladas ({n_unfreeze} top layers)\")\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"Fábrica de modelos lista.\")\n",
    "print(f\"  Backbones disponibles: {list(BACKBONE_CONFIG.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-mlflow",
   "metadata": {},
   "source": [
    "## 6. Configuración MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-mlflow-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"Tracking URI : {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experimento  : {EXPERIMENT_NAME}\")\n",
    "\n",
    "\n",
    "def plot_training_curves(history, run_name, save_path):\n",
    "    \"\"\"Genera y guarda curvas de accuracy y loss.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axes[0].plot(history.history[\"accuracy\"],     label=\"train\", marker='o', ms=3)\n",
    "    axes[0].plot(history.history[\"val_accuracy\"], label=\"val\",   marker='o', ms=3)\n",
    "    axes[0].set_title(f\"Accuracy — {run_name}\")\n",
    "    axes[0].set_xlabel(\"Época\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].plot(history.history[\"loss\"],     label=\"train\", marker='o', ms=3)\n",
    "    axes[1].plot(history.history[\"val_loss\"], label=\"val\",   marker='o', ms=3)\n",
    "    axes[1].set_title(f\"Loss — {run_name}\")\n",
    "    axes[1].set_xlabel(\"Época\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, run_name, save_path):\n",
    "    \"\"\"Genera y guarda la matriz de confusión.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt=\"d\",\n",
    "        xticklabels=CLASS_LABELS,\n",
    "        yticklabels=CLASS_LABELS,\n",
    "        cmap=\"Blues\", ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"Matriz de Confusión — {run_name}\", fontweight='bold')\n",
    "    ax.set_ylabel(\"Real\")\n",
    "    ax.set_xlabel(\"Predicho\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_experiment(run_name, backbone_name, epochs, lr,\n",
    "                  model=None, n_unfreeze=None):\n",
    "    \"\"\"Entrena un modelo y registra todo en MLflow.\n",
    "\n",
    "    Args:\n",
    "        run_name     : nombre del experimento en MLflow\n",
    "        backbone_name: 'ResNet50' | 'EfficientNetB0' | 'MobileNetV2'\n",
    "        epochs       : número máximo de épocas\n",
    "        lr           : learning rate inicial\n",
    "        model        : si se provee, usa este modelo (fine-tuning)\n",
    "        n_unfreeze   : si se provee, descongela top N capas del backbone\n",
    "    Returns:\n",
    "        (model, history, test_accuracy, run_id)\n",
    "    \"\"\"\n",
    "    tmp = \"/tmp\"\n",
    "    tag = run_name.replace(\" \", \"_\")\n",
    "\n",
    "    preprocess_fn = BACKBONE_CONFIG[backbone_name][\"preprocess\"]\n",
    "    ds_train = make_dataset(X_train_p, y_train, training=True,  preprocess_fn=preprocess_fn)\n",
    "    ds_val   = make_dataset(X_val_p,   y_val,   training=False, preprocess_fn=preprocess_fn)\n",
    "    ds_test  = make_dataset(X_test_p,  y_test,  training=False, preprocess_fn=preprocess_fn)\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "\n",
    "        # ── Parámetros ──────────────────────────────────────────────────────\n",
    "        mlflow.log_params({\n",
    "            \"backbone\":       backbone_name,\n",
    "            \"img_size\":       IMG_SIZE,\n",
    "            \"batch_size\":     BATCH_SIZE,\n",
    "            \"epochs\":         epochs,\n",
    "            \"learning_rate\":  lr,\n",
    "            \"fine_tune\":      n_unfreeze is not None,\n",
    "            \"n_unfreeze\":     n_unfreeze,\n",
    "            \"num_classes\":    NUM_CLASSES,\n",
    "            \"train_images\":   len(X_train_p),\n",
    "            \"val_images\":     len(X_val_p),\n",
    "            \"test_images\":    len(X_test_p),\n",
    "            \"augmentation\":   \"flip+rotation+zoom+contrast\",\n",
    "            \"optimizer\":      \"Adam\",\n",
    "            \"loss\":           \"sparse_categorical_crossentropy\",\n",
    "        })\n",
    "\n",
    "        # ── Modelo ──────────────────────────────────────────────────────────\n",
    "        if model is None:\n",
    "            model, _ = build_model(backbone_name)\n",
    "        elif n_unfreeze is not None:\n",
    "            model = unfreeze_top_layers(model, backbone_name, n_unfreeze)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_accuracy\",\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_loss\",\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # ── Entrenamiento ───────────────────────────────────────────────────\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  {run_name}  |  backbone: {backbone_name}  |  lr={lr}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        history = model.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_val,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # ── Log métricas por época ──────────────────────────────────────────\n",
    "        for epoch_i, (tl, ta, vl, va) in enumerate(zip(\n",
    "            history.history[\"loss\"],\n",
    "            history.history[\"accuracy\"],\n",
    "            history.history[\"val_loss\"],\n",
    "            history.history[\"val_accuracy\"],\n",
    "        )):\n",
    "            mlflow.log_metrics({\n",
    "                \"train_loss\":     tl,\n",
    "                \"train_accuracy\": ta,\n",
    "                \"val_loss\":       vl,\n",
    "                \"val_accuracy\":   va,\n",
    "            }, step=epoch_i)\n",
    "\n",
    "        # ── Evaluación en test ──────────────────────────────────────────────\n",
    "        test_loss, test_acc = model.evaluate(ds_test, verbose=0)\n",
    "        mlflow.log_metrics({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n",
    "\n",
    "        y_pred = np.argmax(model.predict(ds_test, verbose=0), axis=1)\n",
    "\n",
    "        # ── Curvas de entrenamiento ─────────────────────────────────────────\n",
    "        curves_path = f\"{tmp}/curves_{tag}.png\"\n",
    "        plot_training_curves(history, run_name, curves_path)\n",
    "        mlflow.log_artifact(curves_path, \"plots\")\n",
    "\n",
    "        # ── Matriz de confusión ─────────────────────────────────────────────\n",
    "        cm_path = f\"{tmp}/cm_{tag}.png\"\n",
    "        plot_confusion_matrix(y_test, y_pred, run_name, cm_path)\n",
    "        mlflow.log_artifact(cm_path, \"plots\")\n",
    "\n",
    "        # ── Reporte de clasificación ────────────────────────────────────────\n",
    "        report = classification_report(\n",
    "            y_test, y_pred, target_names=CLASS_LABELS, digits=4\n",
    "        )\n",
    "        report_path = f\"{tmp}/report_{tag}.txt\"\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"{run_name}\\n{'='*60}\\n\")\n",
    "            f.write(report)\n",
    "        mlflow.log_artifact(report_path, \"reports\")\n",
    "        print(report)\n",
    "\n",
    "        # ── Guardar modelo ──────────────────────────────────────────────────\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"\\n  Test accuracy : {test_acc*100:.2f}%\")\n",
    "        print(f\"  Run ID        : {run_id}\")\n",
    "\n",
    "    return model, history, test_acc, run_id\n",
    "\n",
    "\n",
    "print(\"Funciones de experimento listas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-exp1",
   "metadata": {},
   "source": [
    "## 7. Experimento 1 — ResNet50 (congelado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-exp1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet, hist_resnet, acc_resnet, rid_resnet = run_experiment(\n",
    "    run_name     = \"ResNet50_frozen\",\n",
    "    backbone_name= \"ResNet50\",\n",
    "    epochs       = INITIAL_EPOCHS,\n",
    "    lr           = INITIAL_LR,\n",
    ")\n",
    "print(f\"ResNet50 (frozen) — Test accuracy: {acc_resnet*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-exp2",
   "metadata": {},
   "source": [
    "## 8. Experimento 2 — EfficientNetB0 (congelado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-exp2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_effnet, hist_effnet, acc_effnet, rid_effnet = run_experiment(\n",
    "    run_name     = \"EfficientNetB0_frozen\",\n",
    "    backbone_name= \"EfficientNetB0\",\n",
    "    epochs       = INITIAL_EPOCHS,\n",
    "    lr           = INITIAL_LR,\n",
    ")\n",
    "print(f\"EfficientNetB0 (frozen) — Test accuracy: {acc_effnet*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-exp3",
   "metadata": {},
   "source": [
    "## 9. Experimento 3 — MobileNetV2 (congelado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-exp3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobilenet, hist_mobilenet, acc_mobilenet, rid_mobilenet = run_experiment(\n",
    "    run_name     = \"MobileNetV2_frozen\",\n",
    "    backbone_name= \"MobileNetV2\",\n",
    "    epochs       = INITIAL_EPOCHS,\n",
    "    lr           = INITIAL_LR,\n",
    ")\n",
    "print(f\"MobileNetV2 (frozen) — Test accuracy: {acc_mobilenet*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-compare1",
   "metadata": {},
   "source": [
    "## 10. Comparación Baselines → Selección para Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compare1",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = {\n",
    "    \"ResNet50\":      (acc_resnet,    model_resnet),\n",
    "    \"EfficientNetB0\":(acc_effnet,    model_effnet),\n",
    "    \"MobileNetV2\":   (acc_mobilenet, model_mobilenet),\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"  COMPARACIÓN BASELINES (backbone congelado)\")\n",
    "print(\"=\"*55)\n",
    "for name, (acc, _) in sorted(baseline_results.items(), key=lambda x: -x[1][0]):\n",
    "    bar = \"█\" * int(acc * 40)\n",
    "    print(f\"  {name:<18} {acc*100:5.2f}%  {bar}\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "best_backbone = max(baseline_results, key=lambda k: baseline_results[k][0])\n",
    "best_acc_base = baseline_results[best_backbone][0]\n",
    "best_model    = baseline_results[best_backbone][1]\n",
    "\n",
    "print(f\"\\n  Mejor baseline : {best_backbone} ({best_acc_base*100:.2f}%)\")\n",
    "print(f\"  → Procedemos con fine-tuning de {best_backbone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-finetune",
   "metadata": {},
   "source": [
    "## 11. Experimento 4 — Fine-tuning del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-finetune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelamos las últimas 50 capas del backbone\n",
    "N_UNFREEZE = 50\n",
    "\n",
    "model_ft, hist_ft, acc_ft, rid_ft = run_experiment(\n",
    "    run_name     = f\"{best_backbone}_finetuned\",\n",
    "    backbone_name= best_backbone,\n",
    "    epochs       = FINE_TUNE_EPOCHS,\n",
    "    lr           = FINE_TUNE_LR,\n",
    "    model        = best_model,\n",
    "    n_unfreeze   = N_UNFREEZE,\n",
    ")\n",
    "print(f\"{best_backbone} (fine-tuned) — Test accuracy: {acc_ft*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-final-compare",
   "metadata": {},
   "source": [
    "## 12. Comparación Final de Todos los Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-final-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {\n",
    "    \"ResNet50\\n(frozen)\":           acc_resnet,\n",
    "    \"EfficientNetB0\\n(frozen)\":     acc_effnet,\n",
    "    \"MobileNetV2\\n(frozen)\":        acc_mobilenet,\n",
    "    f\"{best_backbone}\\n(fine-tuned)\": acc_ft,\n",
    "}\n",
    "all_models = {\n",
    "    \"ResNet50\\n(frozen)\":           model_resnet,\n",
    "    \"EfficientNetB0\\n(frozen)\":     model_effnet,\n",
    "    \"MobileNetV2\\n(frozen)\":        model_mobilenet,\n",
    "    f\"{best_backbone}\\n(fine-tuned)\": model_ft,\n",
    "}\n",
    "\n",
    "names = list(all_results.keys())\n",
    "accs  = [v * 100 for v in all_results.values()]\n",
    "colors= ['steelblue', 'darkorange', 'seagreen', 'crimson']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 5))\n",
    "bars = ax.bar(names, accs, color=colors, edgecolor='black', width=0.55)\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_ylabel(\"Test Accuracy (%)\", fontsize=12)\n",
    "ax.set_title(\"Comparación de Modelos — Test Accuracy\", fontsize=14, fontweight='bold')\n",
    "ax.axhline(y=max(accs), color='red', linestyle='--', alpha=0.4, label=f'Mejor: {max(accs):.2f}%')\n",
    "ax.legend()\n",
    "for bar, acc in zip(bars, accs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.8,\n",
    "            f\"{acc:.2f}%\", ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "plt.tight_layout()\n",
    "comparison_path = \"/tmp/model_comparison.png\"\n",
    "plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Log del gráfico de comparación en MLflow\n",
    "with mlflow.start_run(run_name=\"summary_comparison\"):\n",
    "    for name, acc in zip(names, accs):\n",
    "        mlflow.log_metric(name.replace(\"\\n\", \"_\").replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"),\n",
    "                          acc / 100)\n",
    "    mlflow.log_artifact(comparison_path, \"plots\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"  RESULTADOS FINALES\")\n",
    "print(\"=\"*55)\n",
    "for name, acc in sorted(zip(names, accs), key=lambda x: -x[1]):\n",
    "    marker = \"  ← GANADOR\" if acc == max(accs) else \"\"\n",
    "    print(f\"  {name.replace(chr(10), ' '):<30} {acc:5.2f}%{marker}\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "winner_name = names[np.argmax(accs)]\n",
    "winner_model = all_models[winner_name]\n",
    "print(f\"\\nModelo ganador: {winner_name.replace(chr(10), ' ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-save",
   "metadata": {},
   "source": [
    "## 13. Guardar el Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir  = f\"./best_model_{timestamp}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Guardar modelo en formato SavedModel (TF nativo)\n",
    "winner_model.save(f\"{save_dir}/model\")\n",
    "\n",
    "# Metadata para servir el modelo\n",
    "metadata = {\n",
    "    \"classes\":        CLASSES,\n",
    "    \"class_labels\":   CLASS_LABELS,\n",
    "    \"img_size\":       IMG_SIZE,\n",
    "    \"num_classes\":    NUM_CLASSES,\n",
    "    \"winner_model\":   winner_name.replace(\"\\n\", \" \"),\n",
    "    \"test_accuracy\":  round(float(max(accs)) / 100, 4),\n",
    "    \"all_results\":    {n.replace(\"\\n\", \" \"): round(a/100, 4) for n, a in zip(names, accs)},\n",
    "    \"timestamp\":      timestamp,\n",
    "    \"train_images\":   int(len(X_train_p)),\n",
    "    \"val_images\":     int(len(X_val_p)),\n",
    "    \"test_images\":    int(len(X_test_p)),\n",
    "}\n",
    "with open(f\"{save_dir}/metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Modelo guardado en : {save_dir}/model\")\n",
    "print(f\"Metadata en        : {save_dir}/metadata.json\")\n",
    "print(f\"\\nResumen:\")\n",
    "for k, v in metadata.items():\n",
    "    if k != \"all_results\":\n",
    "        print(f\"  {k:<20}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": [
    "## 14. Resumen de Experimentos MLflow\n",
    "\n",
    "Para ver los experimentos en MLflow:\n",
    "\n",
    "```bash\n",
    "# Local\n",
    "mlflow ui --port 5000\n",
    "\n",
    "# EC2 (ejecutar en el servidor)\n",
    "mlflow server --host 0.0.0.0 --port 5000\n",
    "\n",
    "# Luego abrir en el navegador:\n",
    "# http://localhost:5000   (local)\n",
    "# http://<EC2-IP>:5000    (EC2)\n",
    "```\n",
    "\n",
    "### Variables de entorno para EC2\n",
    "```bash\n",
    "export MLFLOW_TRACKING_URI=http://<EC2-IP>:5000\n",
    "export STREET_DATA_DIR=/ruta/a/street_data\n",
    "jupyter nbconvert --to notebook --execute train_model.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
